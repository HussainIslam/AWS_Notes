# Monitoring, Troubleshooting, and Audit

## Monitoring 
* CloudWatch
	* Metrics: collect/track metrics
	* Logs: collect/monitor/analyze/store log files
	* Events: send notifications
	* Alarms: react in real-time to metrics/events
* X-Ray:
	* troubleshooting
	* distributed tracing of microservices
* CloudTrail:
	* Internal monitoring of API calls
	* audit changes to AWS resources by users

## CloudWatch
* Metric is a variable to monitor
* metrics are grouped by namespaces
* Dimension is an attribute of a metric (eg instance id)
* upto 10 dimensions per metric
* Metrics have timestamps
* can create dashboards
* EC2 Detialed Monitoring:
	* default every 5 minutes
	* can be set to 1 minute with additional cost
	* EC2 Memory usage is not pushed by default but can be setup as custom metric
* Custom Metrics
	* can set up custom metrics
	* can use dimensions to segment metrics
	* Metric resolution:
		* standard: 1 minute
		* High Resolution: upto 1 second with higher cost(API Call is called StorageResolution)
	* To send a metric call PutMetricData API
	* if sending too much data use exponential back off
* Alarms
	* trigger notification by metrics
	* can be attached to EC2 Actions or SNS Notifications
	* Stages:
		1. OK
		2. INSUFFICIENT_DATA
		3. ALARM
	* Period:
		* length of time in seconds to evaluate metrics
		* with High Resolution can choose 10 or 30 sec
* Logs
	* applications can send logs to cloudwatch using SDK
	* CloudWatch can collect log from:
		* Elastic Beanstalk (application logs)
		* ECS (from containers)
		* AWS Lambda (function logs)
		* VPC Flow Logs
		* API Gateway
		* CloudTrail based filter
		* CloudWatch log agents: eg EC2 machines
		* Route53: Log DNS queries
	* Processed in cloudwatch/stored in S3/streamed to ElasticSearch cluster
	* can use filter expressions
	* storage architecture:
		* Log Groups: arbitrary names for application
		* Log stream: instances within app/log files/containers
	* can define log expiration policy (how many days)
	* can use AWS CLI to tail logs
	* need to make sure IAM permissions are correct
	* encrypted with KMS for logs at rest
* CloudWatch Agent
	* by default not logs are going from EC2 instances
	* need to run Cloudwatch Agent to push log files
	* need to make sure IAM permissions are correct
	* the Agent can be setup on-premises too
	* there are two agents:
		* logs agent (old): can only send to CloudWatch Logs; by default high level
		* unified agent: collect additional system level metrics; centralized config using SSM Parameter Store
			* CPU: active, gues, idle, system, user, steal
			* Disk Metrics
			* Disk IO
			* RAM
			* Netstat: number of TCP/UDP connections, net packets, bytes
			* Processes
			* Swap space
* CloudWatch Logs Metric Filter
	* can use filter expressions
		* find specific IP
		* Count something
		* can be used to trigger alarm
	* not retroactive; only publish data points after the filer was created
	* Filter Reference: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html
* CloudWatch Events
	* can schedule with cron jobs
	* can define event pattern (eg CodePipeline state changes)
	* can trigger to Lambda functions, SQS/SNS/Kinesis messages
	* creates a small JSON document

## Amazon EventBridge
* next evolution of CloudWatch Events
* Default event bus: generated by AWS Services
* Partner Event bus: receives events from SaaS (Zendesk, DataDog, Segment, Auth0)
* Custom event bus: own applications
* possible to do cross account event 
* Can create rules
* EventBridge can analyze events in bus and infer schema (data structure), which can allow code for app 
* Schema can have versions
* builds on CloudWatch Events

## AWS X-Ray
* Visual analysis of the application
* can troubleshoot performance (bottleneck)
* understand dependencies in a microservice architecture
* pinpoint issues
* review request behaviors
* find errors and exceptions
* Compatibility:
	* Lambda
	* beanstalk
	* ECS
	* ELB
	* API Gateway
	* EC2 and on-premise
* Tracing:
	* end-to-end way to following a request
	* each component dealing with the request add it's own trace
	* tracing is made of segments and sub-segments
	* annotations can be added to traces for extra-information
* security:
	* IAM for auth
	* KMS for encryption at rest
* how to enable:
	1. Code must import AWS XRAY SDK
	2. install XRAY daemon or enable XRAY integration in AWS
* X-Ray troubleshooting
	* not working on EC2
		* check IAM role
		* Check X-Ray Daemon
	* AWS Lambda
		* check IAM execution role with proper policy (AWSX-RayWriteOnlyAccess)
		* check X-Ray is imported in code
* APIs
	* Write API
		* PutTraceSegments: Uploads segment documents
		* PutTelemetryRecords: upload telemetry (SegmentsReceivedCount, SegementsRejectedCounts, BackendConnectionErrors)
		* GetSamplingRules: Retrieve all sampling rules to know sampling rules are changing
		* GetSamplingTargets
		* GetSamplingStatisticSummaries
	* Read API
		* GetSamplingRules
		* GetSamplingTargets
		* GetSamplingStatisticSummaries
		* BatchGetTraces: list of traces; each trace is a segment of documents
		* GetServiceGraph: main graph
		* GetTraceGraph: get a specific service graph 
		* GetTraceSummaries: get IDs and annotations for traces available
		* GetGroups
		* GetGroup
		* GetTimeSeriesServiceStatistics
* Integrate with Beanstalk
	* beanstalk includes X-Ray Daemon
	* the daemon can be run setting an option in EB Console or config file (`.ebextensions/xray-daemon.config`)
	* make sure instance profile has correct IAM
	* make sure the code includes X-Ray SDK 
	* not provided for multi-docker containers
* Integrate with ECS
	1. Use X-Ray container as daemon. daemon will run in all EC2 instances
	2. Side car Pattern: extra container with each app container
	3. For Fargate Cluster must be used as Side Car Pattern 

## X-Ray Instrumentation
* means the measure of product's performance, diagnose errors, and to write trace information
* to instrument, need to use X-Ray SDK
* can use either interceptors, filters, handlers, middlwares based on the code
* Concepts:
	* segments: each app/service will send
	* subsegments: more details
	* trace: segments collected together to form end-to-end trace
	* sampling: decrease amount of requests sent to x-ray; reduces cost
		* control the amount of data
		* Default: records first request each second (reservoir) and 5% of additional requests (rate)
	* Annotations: key value pairs to index traces and filter them
	* Metadata: key value pairs for searching; not indexed

## CloudTrail
* provides governance, compliance and audit
* enabled by default
* get history of account by:
	* console
	* SDK
	* CLI
	* AWS Services
* Can put logs from CloudTrail to CloudWatch Logs
* if someone did something, look into CloudTrail First

## CloudTrail vs CloudWatch vs X-Ray
* CloudTrail is used to audit API calls by users/services/Consoles; helpful to detect changes
* CloudWatch for monitoring and logs
* X-Ray auto trace analysis and central service map visualization; latency, error, fault analysis